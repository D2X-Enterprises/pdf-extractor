# ğŸ“„ Concurrent PDF OCR Extractor

<div align="center">

**Transform unsearchable PDFs into actionable text with AI-powered extraction**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Tesseract](https://img.shields.io/badge/OCR-Tesseract-orange.svg)](https://github.com/tesseract-ocr/tesseract)

</div>

---

## ğŸ¯ Overview

A powerful, production-ready Python tool designed for **writers**, **researchers**, **journalists**, and the **OSINT community** who need to quickly and accurately extract text from large volumes of scanned or image-based PDF documents.

By leveraging **concurrent processing**, **high-DPI rendering**, and **batch directory processing**, this tool transforms unsearchable PDFs into usable, indexed text for analysis and citationâ€”complete with AI-powered name detection and comprehensive word analytics.

---

## âœ¨ Features

### ğŸš€ **Performance & Reliability**
- **âš¡ Concurrent Processing** â€” Utilizes multiple CPU cores to process pages simultaneously, dramatically reducing extraction time
- **ğŸ“ Batch Directory Processing** â€” Process entire folders of PDFs automatically with uninterrupted workflow
- **ğŸ”„ Resume Capability** â€” Automatically detects partial output and allows resuming from the last successfully completed page
- **ğŸ¯ High Accuracy** â€” Renders PDF pages to high-resolution PNGs (default 300 DPI) for superior OCR results
- **ğŸ›¡ï¸ Robust Error Handling** â€” Continues processing even if individual files fail, with detailed error logging

### ğŸ“Š **Advanced Analytics**
- **ğŸ“ˆ Word Count Analysis** â€” Generates comprehensive CSV reports with:
  - Total document word count
  - Per-page word counts
  - Individual word occurrence tracking with page numbers
  
- **ğŸ‘¤ AI-Powered Name Detection** â€” Uses Named Entity Recognition (NER) to identify and track person names:
  - Occurrence counts for each name
  - Page numbers where each name appears
  - Exported to CSV for easy analysis

### ğŸ› ï¸ **User-Friendly Interface**
- **ğŸ’» Command-Line Interface (CLI)** â€” Easy configuration via command-line arguments
- **ğŸ“¦ Output Consolidation** â€” Merges all extracted text into a single `combined_output.txt` file
- **ğŸŒ Multi-Language Support** â€” Process documents in multiple languages simultaneously
- **ğŸ“ Detailed Logging** â€” Automatic error logging for failed documents with timestamps

---

## ğŸ“‹ Prerequisites

### ğŸ **1. Python 3**

Requires **Python 3.8 or newer**

```bash
python3 --version  # Verify your Python version
```

### ğŸ” **2. Tesseract OCR Engine**

Tesseract is the core OCR engine used by this script.

#### **Installation:**

**macOS** (using Homebrew):
```bash
brew install tesseract
```

**Linux** (using apt):
```bash
sudo apt install tesseract-ocr
```

**Windows**:
- Download the installer from the [Tesseract GitHub](https://github.com/tesseract-ocr/tesseract)
- Note the installation path for the `--tesseract-path` argument

#### **Language Packs:**
For languages other than English, install the corresponding Tesseract language packs:
```bash
# Example: French
sudo apt install tesseract-ocr-fra

# Example: German
sudo apt install tesseract-ocr-deu
```

### ğŸ“š **3. Required Python Libraries**

All dependencies are listed in `requirements.txt`:

- **PyMuPDF** (fitz) â€” PDF rendering
- **Pillow/pytesseract** â€” OCR processing
- **spaCy** â€” Named Entity Recognition (proper name detection)

---

## ğŸš€ Installation & Setup

### **Option 1: Automated Setup** â­ **(Recommended)**

Run the installation script to automatically set up everything:

```bash
chmod +x install.sh
./install.sh
```

**This script will:**
- âœ… Check for Python and Tesseract
- âœ… Create a virtual environment
- âœ… Install all dependencies from `requirements.txt`
- âœ… Download the spaCy language model

---

### **Option 2: Manual Setup**

#### **Step 1: Clone the Repository**

```bash
git clone <repository-url>
cd pdf-extractor
```

#### **Step 2: Create Virtual Environment**

It is **highly recommended** to use a virtual environment:

```bash
# Create virtual environment
python3 -m venv venv

# Activate virtual environment
# Linux/macOS:
source venv/bin/activate

# Windows (CMD):
venv\Scripts\activate

# Windows (PowerShell):
.\venv\Scripts\Activate.ps1
```

#### **Step 3: Install Dependencies**

```bash
# Install Python packages
pip install -r requirements.txt

# Download spaCy language model for name detection
python -m spacy download en_core_web_sm
```

---

## ğŸ’» Usage

### **Basic Execution**

#### **Single PDF File:**
Run the script with the path to your PDF file:

```bash
python pdf_extractor.py path/to/your/document.pdf
```

**The script will:**
1. âœ… Check for previous progress
2. âœ… Prompt you to process all pages, resume, or select a specific range

#### **Directory of PDFs (Batch Mode):** ğŸ†•
Process all PDFs in a directory automatically:

```bash
python pdf_extractor.py path/to/pdf_folder/
```

**In batch mode, the script will:**
1. âœ… Automatically detect all PDF files in the directory
2. âœ… Process each PDF with ALL pages (no prompts)
3. âœ… Continue processing even if individual files fail
4. âœ… Log errors to `error_log.txt` in the source directory
5. âœ… Provide a comprehensive summary at completion

---

### **Resume an Interrupted Job**

If processing was interrupted, simply rerun the command:

```bash
python pdf_extractor.py my_long_report.pdf
```

**Example output:**
```
Found existing files. Last successfully processed page was 50 of 100.
Enter 'r' to resume at page 51, 'a' for all, 'n' for a new range, or 'q' to quit: r
```

> **Note:** Resume capability is available for single PDF files only. In batch mode, each PDF starts fresh.

---

### **âš™ï¸ Advanced Arguments**

Customize processing with these optional flags:

| Argument | Default | Description |
|----------|---------|-------------|
| **`[PDF_PATH]`** | *Required* | Path to input PDF file **OR** directory containing PDFs |
| `--output-dir` | `.` | Base directory where processing folders will be created |
| `--dpi` | `300` | Rendering quality (DPI). Higher = better OCR but slower |
| `--lang` | `eng` | Tesseract language code(s). Use `+` to combine (e.g., `eng+deu`) |
| `--tesseract-path` | `/usr/bin/tesseract` | Full path to Tesseract executable (crucial for Windows) |

---

### **ğŸ“ Command Examples**

#### **1. Single PDF - High-Quality Processing (600 DPI) with Multiple Languages:**

```bash
python pdf_extractor.py thesis.pdf --dpi 600 --lang eng+fra
```

When prompted:
```
Enter 'a' for all pages, 'n' for a new range (e.g., 5-10), or 'q' to quit: n
Enter page range (e.g., 5-10): 1-50
```

#### **2. Batch Processing - Entire Directory:**

```bash
python pdf_extractor.py ./research_papers/ --dpi 300 --lang eng
```

**Output:**
```
======================================================================
BATCH PROCESSING MODE
======================================================================
Found 5 PDF file(s) in directory: ./research_papers/
Processing mode: ALL PAGES (automatic for batch mode)
======================================================================

Processing PDF 1/5: paper_001.pdf
[Processing details...]
âœ“ SUCCESS: paper_001.pdf completed successfully

Processing PDF 2/5: paper_002.pdf
[Processing details...]
âœ“ SUCCESS: paper_002.pdf completed successfully
...
```

#### **3. Windows with Custom Tesseract Path:**

```bash
python pdf_extractor.py my_doc.pdf --tesseract-path "C:\Program Files\Tesseract-OCR\tesseract.exe"
```

#### **4. Batch Processing with Custom Output Directory:**

```bash
python pdf_extractor.py ./invoices/ --output-dir ./processed_invoices --dpi 300
```

---

## ğŸ“‚ Output Structure

### **Single PDF Output:**

A new directory named `<pdf_name>_processed` will be created:

```
<pdf_name>_processed/
â”œâ”€â”€ ğŸ“„ combined_output.txt          # Final merged text document
â”œâ”€â”€ ğŸ“Š word_count_report.csv        # Word count analysis
â”œâ”€â”€ ğŸ‘¤ proper_names_report.csv      # AI-detected person names
â”œâ”€â”€ ğŸ–¼ï¸  png_images/
â”‚   â”œâ”€â”€ 0001.png
â”‚   â”œâ”€â”€ 0002.png
â”‚   â””â”€â”€ ...
â””â”€â”€ ğŸ“ text_files/
    â”œâ”€â”€ 0001.txt                    # Text output for page 1
    â”œâ”€â”€ 0002.txt                    # Text output for page 2
    â””â”€â”€ ...
```

### **Batch Processing Output:**

When processing a directory, each PDF gets its own output folder:

```
output_directory/
â”œâ”€â”€ document1_processed/
â”‚   â”œâ”€â”€ combined_output.txt
â”‚   â”œâ”€â”€ word_count_report.csv
â”‚   â”œâ”€â”€ proper_names_report.csv
â”‚   â”œâ”€â”€ png_images/
â”‚   â””â”€â”€ text_files/
â”œâ”€â”€ document2_processed/
â”‚   â””â”€â”€ ...
â””â”€â”€ document3_processed/
    â””â”€â”€ ...
```

### **Error Logging (Batch Mode):** ğŸ†•

If any PDFs fail during batch processing, errors are logged in the source directory:

```
source_directory/
â”œâ”€â”€ document1.pdf
â”œâ”€â”€ document2.pdf
â”œâ”€â”€ corrupted.pdf
â””â”€â”€ error_log.txt              # â† Detailed error information
```

**Error log format:**
```
======================================================================
[2024-12-21 14:30:45] ERROR processing: corrupted.pdf
----------------------------------------------------------------------
PyPdfError: EOF marker not found
======================================================================
```

> **ğŸ’¡ Note:** If a page fails OCR, its `.txt` file will contain an "OCR FAILED" marker with the error message. Failed pages are automatically skipped during consolidation.

---

## ğŸ“Š CSV Reports

The extractor automatically generates two powerful CSV reports for analysis:

### **1. ğŸ“ˆ Word Count Report** (`word_count_report.csv`)

Provides comprehensive word statistics:

#### **Document Summary Section:**
- ğŸ“– Total word count across all pages
- ğŸ“„ Number of pages analyzed
- ğŸ”¤ Count of unique words

#### **Per-Page Word Counts:**
- ğŸ“Š Individual word count for each page

#### **Word Occurrence Details:**
- ğŸ” Every unique word (3+ characters)
- ğŸ”¢ Total occurrences
- ğŸ“ All page numbers where it appears

**Example:**
```csv
Word,Total Occurrences,Pages
dog,75,"3, 36, 73, 89, 102"
cat,42,"5, 12, 89"
research,156,"1, 2, 5, 8, 12, 15, 23, 45, 67, 89"
```

---

### **2. ğŸ‘¤ Proper Names Report** (`proper_names_report.csv`)

Identifies person names using **AI-powered Named Entity Recognition**:

#### **Contents:**
- ğŸ‘¥ Person names detected in the document
- ğŸ”¢ Total occurrences for each name
- ğŸ“ All page numbers where the name appears
- ğŸ“Š Sorted by frequency (most common first)

**Example:**
```csv
Name,Total Occurrences,Pages
John Smith,92,"254, 340, 533, 678"
Jane Doe,45,"12, 89, 234, 456"
Dr. Sarah Johnson,23,"5, 67, 89"
```

> **âš ï¸ Note:** Proper name detection requires spaCy and the English language model. If not installed, this feature will be skipped with a warning message.

---

## ğŸ”„ Batch Processing Workflow

### **Example Scenario:**

You have a folder of 50 scanned research papers that need OCR processing.

```bash
# Step 1: Organize PDFs
mkdir research_papers
cp *.pdf research_papers/

# Step 2: Run batch processing
python pdf_extractor.py research_papers/ --dpi 300 --output-dir ./extracted

# Step 3: Review results
ls extracted/
# Shows: paper1_processed/, paper2_processed/, etc.

# Step 4: Check for errors (if any)
cat research_papers/error_log.txt
```

### **Batch Processing Features:**

âœ… **Automatic Processing** â€” No manual intervention required  
âœ… **Error Resilience** â€” Failed PDFs don't stop the batch  
âœ… **Detailed Logging** â€” Know exactly what succeeded and what failed  
âœ… **Progress Tracking** â€” See real-time progress for each PDF  
âœ… **Summary Report** â€” Comprehensive statistics at completion  

---

## ğŸ› Troubleshooting

### **Q: What happens if one PDF in a batch is corrupted?**
**A:** The script logs the error to `error_log.txt` in the source directory and continues processing the remaining PDFs. You can review the error log after completion and re-process failed files individually if needed.

### **Q: Can I resume a failed batch?**
**A:** Simply re-run the same command. The script will skip PDFs that already have complete output directories, effectively resuming where it left off.

### **Q: How do I process only specific pages in batch mode?**
**A:** Batch mode always processes ALL pages automatically. For page-specific processing, process files individually instead.

### **Q: Where do error logs go?**
**A:** Error logs are saved as `error_log.txt` in the **source directory** (where the PDFs are located), not in the output directory.

### **Q: Can I process subdirectories?**
**A:** Not currentlyâ€”only PDFs in the specified directory are processed (non-recursive). Subdirectories are not scanned.

### **Q: What if processing is too slow?**
**A:** Try reducing the `--dpi` value (e.g., `--dpi 200`). Lower DPI means faster processing but slightly reduced OCR accuracy.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Tesseract OCR** â€” Google's powerful open-source OCR engine
- **PyMuPDF** â€” Fast and efficient PDF rendering
- **spaCy** â€” Industrial-strength Natural Language Processing

---

<div align="center">

**Made with â¤ï¸ for the research and OSINT community**

â­ Star this repo if you find it useful!

</div>
